{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Image and Video Datasets\n",
    "In this notebook, we will be creating our datasets from which to perform a single-shot face classifier from images on videos. Thye subject matter: Brazilian Jiu Jitsu No Gi Worlds Championships in December 2023. \n",
    "\n",
    "The single reference images will come from professional winning photos of the athletes as posted on the IBJJF Facebook page. The source videos will be extracted from the IBJJF's public YouTube page.\n",
    "\n",
    "We will use OpenCV's Haar Cascade classifier to detect faces and their locations using bounding boxes. \n",
    "\n",
    "Image & Video Datasets:\n",
    "- Image dataset: podium photos from a major tournament for facial recognition\n",
    "    - IBJJF Podium Pics from the 2023 No Gi Worlds Tournament https://www.facebook.com/media/set/?set=a.728657779287780&type=3\n",
    "- Video dataset: Black Belt matches on IBJJF's YouTube channel\n",
    "    - IBJJF YouTube Playlist https://www.youtube.com/watch?v=VZN9Di_Ou-c&list=PLndFOMjO-W278-AspLyh5IWGC7eNQmF4U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytube import Playlist, YouTube\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Download Images \n",
    "Podium pics are on Facebook and since there are less than 20 iamges, we will manually download them and skip the Facebook API process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save videos\n",
    "save_path = r'your_path'\n",
    "\n",
    "# URL of the YouTube playlist\n",
    "playlist_url = 'https://www.youtube.com/watch?v=VZN9Di_Ou-c&list=PLndFOMjO-W278-AspLyh5IWGC7eNQmF4U'\n",
    "\n",
    "# Use the PyTube library to extract the playlist\n",
    "playlist = Playlist(playlist_url)\n",
    "\n",
    "# Loop through each video in the playlist\n",
    "for video in playlist.video_urls:\n",
    "    try:\n",
    "        # Use the PyTube library to extract the video\n",
    "        yt = YouTube(video)\n",
    "        # Get the highest resolution stream\n",
    "        stream = yt.streams.get_highest_resolution()\n",
    "        # Download the video\n",
    "        stream.download(output_path=save_path)\n",
    "        print(f\"Downloaded: {yt.title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {video}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple command line version for downloading an entire playlit\n",
    "# pytube 'https://www.youtube.com/watch?v=VZN9Di_Ou-c&list=PLndFOMjO-W278-AspLyh5IWGC7eNQmF4U'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r'your_path'\n",
    "\n",
    "# Create a list of image files and their paths \n",
    "image_files = glob.glob(save_path + '/*.jpg')\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually inspect the image\n",
    "img = Image.open(image_files[1])\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haar Cascade Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single image to test the face detector\n",
    "img = cv2.imread(image_files[1])\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define the cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detect faces, use higher scale factor to reduce false positives\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Draw bounding boxes\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
    "    \n",
    "pil_img = Image.fromarray(img)\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "    img = cv2.imread(image)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "face_dict = {}\n",
    "\n",
    "for i in image_files:\n",
    "    face_roi = detect_faces(i)\n",
    "    file_name = os.path.basename(i)\n",
    "    face_dict[file_name] = face_roi\n",
    "\n",
    "face_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(face_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
